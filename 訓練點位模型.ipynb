{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b08b6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0505b0cd",
   "metadata": {},
   "source": [
    "# 第一次訓練點位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f64af98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\compat\\_optional.py:132\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 132\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:984\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openpyxl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# 1. 讀取Excel檔案\u001b[39;00m\n\u001b[0;32m     11\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/user/點位記錄整理.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 12\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 2. 整理資料\u001b[39;00m\n\u001b[0;32m     15\u001b[0m features \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msy\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\io\\excel\\_base.py:504\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    503\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1580\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m engine\n\u001b[0;32m   1578\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options \u001b[38;5;241m=\u001b[39m storage_options\n\u001b[1;32m-> 1580\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1581\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1584\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:552\u001b[0m, in \u001b[0;36mOpenpyxlReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;129m@doc\u001b[39m(storage_options\u001b[38;5;241m=\u001b[39m_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    539\u001b[0m     engine_kwargs: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    540\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    541\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03m    Reader using openpyxl engine.\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;124;03m        Arbitrary keyword arguments passed to excel engine.\u001b[39;00m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 552\u001b[0m     \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopenpyxl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    554\u001b[0m         filepath_or_buffer,\n\u001b[0;32m    555\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    556\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m    557\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\compat\\_optional.py:135\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 135\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. 讀取Excel檔案\n",
    "data_path = \"C:/Users/user/點位記錄整理.xlsx\"\n",
    "df = pd.read_excel(data_path)\n",
    "\n",
    "# 2. 整理資料\n",
    "features = df[['px', 'py', 'sx', 'sy']].values\n",
    "targets = df[['x', 'y']].values\n",
    "\n",
    "# 標準化特徵\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# 分割資料為訓練集和測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, targets, test_size=0.3, random_state=42)\n",
    "\n",
    "# 轉換為PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# 3. 建立深度學習模型\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, 32)\n",
    "        self.layer4 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = torch.relu(self.layer3(x))\n",
    "        return self.layer4(x)\n",
    "\n",
    "model = NeuralNetwork(X_train.shape[1])\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# 4. 訓練模型\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        inputs = X_train[i:i+batch_size]\n",
    "        labels = y_train[i:i+batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 計算驗證集上的損失\n",
    "    val_outputs = model(X_test)\n",
    "    val_loss = criterion(val_outputs, y_test)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}, Validation Loss: {val_loss.item()}\")\n",
    "\n",
    "# 5. 儲存模型\n",
    "torch.save(model.state_dict(), 'trained_model.pth')\n",
    "print(\"模型訓練完畢並已儲存!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af36f90",
   "metadata": {},
   "source": [
    "# 新增數據校正後再次訓練點位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1552738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. 讀取Excel檔案\n",
    "data_path = \"C:/Users/user/點位記錄整理.xlsx\"\n",
    "df = pd.read_excel(data_path)\n",
    "\n",
    "# 2. 整理資料\n",
    "features = df[['px', 'py', 'sx', 'sy']].values\n",
    "targets = df[['x', 'y']].values\n",
    "\n",
    "# 標準化特徵\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# 分割資料為訓練集和測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, targets, test_size=0.3, random_state=42)\n",
    "\n",
    "# 轉換為PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# 3. 建立深度學習模型\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, 32)\n",
    "        self.layer4 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = torch.relu(self.layer3(x))\n",
    "        return self.layer4(x)\n",
    "\n",
    "model = NeuralNetwork(X_train.shape[1])\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# 4. 訓練模型\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        inputs = X_train[i:i+batch_size]\n",
    "        labels = y_train[i:i+batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 計算驗證集上的損失\n",
    "    val_outputs = model(X_test)\n",
    "    val_loss = criterion(val_outputs, y_test)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}, Validation Loss: {val_loss.item()}\")\n",
    "\n",
    "# 5. 儲存模型\n",
    "torch.save(model.state_dict(), 'trained_model20231001.pth')\n",
    "print(\"模型訓練完畢並已儲存!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2e2a18",
   "metadata": {},
   "source": [
    "# 進行預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3536a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac9c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 定義神經網路結構\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, 32)\n",
    "        self.layer4 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = torch.relu(self.layer3(x))\n",
    "        return self.layer4(x)\n",
    "\n",
    "# 載入模型參數\n",
    "model = NeuralNetwork(4)\n",
    "model.load_state_dict(torch.load('trained_model20231001.pth'))\n",
    "model.eval()\n",
    "\n",
    "# 載入標準化器\n",
    "data_path = \"C:/Users/user/點位記錄整理.xlsx\"\n",
    "df = pd.read_excel(data_path)\n",
    "features = df[['px', 'py', 'sx', 'sy']].values\n",
    "scaler = StandardScaler().fit(features)\n",
    "\n",
    "# 讓使用者輸入數據\n",
    "px_value = float(input(\"請輸入 px 的值: \"))\n",
    "py_value = float(input(\"請輸入 py 的值: \"))\n",
    "sx_value = float(input(\"請輸入 sx 的值: \"))\n",
    "sy_value = float(input(\"請輸入 sy 的值: \"))\n",
    "\n",
    "# 將輸入數據標準化\n",
    "sample_data = scaler.transform([[px_value, py_value, sx_value, sy_value]])\n",
    "sample_data = torch.tensor(sample_data, dtype=torch.float32)\n",
    "\n",
    "# 使用模型進行預測\n",
    "predicted_output = model(sample_data)\n",
    "predicted_x, predicted_y = predicted_output[0].detach().numpy()\n",
    "\n",
    "print(f\"預測的 x 值為: {predicted_x:.2f}\")\n",
    "print(f\"預測的 y 值為: {predicted_y:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fc56b6",
   "metadata": {},
   "source": [
    "# 手動輸入4值預測獲得x y，並做為輸入來驅動滑台"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91465af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import serial\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# 定義神經網路結構\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, 32)\n",
    "        self.layer4 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = torch.relu(self.layer3(x))\n",
    "        return self.layer4(x)\n",
    "\n",
    "# 載入模型參數\n",
    "model = NeuralNetwork(4)\n",
    "model.load_state_dict(torch.load('trained_model20231001.pth'))\n",
    "model.eval()\n",
    "\n",
    "# 載入標準化器\n",
    "data_path = \"C:/Users/user/點位記錄整理.xlsx\"\n",
    "df = pd.read_excel(data_path)\n",
    "features = df[['px', 'py', 'sx', 'sy']].values\n",
    "scaler = StandardScaler().fit(features)\n",
    "\n",
    "class StageCommander:\n",
    "    def __init__(self, port='COM3', baudrate=38400):\n",
    "        self.ser = serial.Serial(port, baudrate)\n",
    "        self.ser.timeout = 0.05\n",
    "        self.x_position = 0\n",
    "        self.y_position = 0\n",
    "    \n",
    "    def send_command(self, command):\n",
    "        self.ser.write((command + '\\r').encode())\n",
    "        time.sleep(0.01)\n",
    "        return self.ser.readline().decode().strip()\n",
    "    \n",
    "    def set_pulse(self, axis, pulse):\n",
    "        command = f\"AXI{axis}:PULSe {pulse}\"\n",
    "        response = self.send_command(command)\n",
    "    \n",
    "    def drive_to_relative_position(self, x_pulse, y_pulse, wait_time=0):\n",
    "        start_time = time.time()\n",
    "        x_direction = 'X+' if x_pulse > 0 else 'X-'\n",
    "        y_direction = 'Y+' if y_pulse > 0 else 'Y-'\n",
    "        position = f\"{x_direction}{y_direction}\"\n",
    "        command = f\"GOLI {position}\"\n",
    "        response = self.send_command(command)\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"Response: {response}, Elapsed time: {elapsed_time} seconds\")\n",
    "        time.sleep(wait_time)\n",
    "        \n",
    "        # 更新座標\n",
    "        if 'X+' in position:\n",
    "            self.x_position += abs(x_pulse)\n",
    "        elif 'X-' in position:\n",
    "            self.x_position -= abs(x_pulse)\n",
    "        if 'Y+' in position:\n",
    "            self.y_position += abs(y_pulse)\n",
    "        elif 'Y-' in position:\n",
    "            self.y_position -= abs(y_pulse)\n",
    "    \n",
    "    def get_position(self):\n",
    "        return self.x_position, self.y_position\n",
    "    \n",
    "    def close(self):\n",
    "        self.ser.close()\n",
    "\n",
    "# 讓使用者輸入數據\n",
    "px_value = float(input(\"請輸入 px 的值: \"))\n",
    "py_value = float(input(\"請輸入 py 的值: \"))\n",
    "sx_value = float(input(\"請輸入 sx 的值: \"))\n",
    "sy_value = float(input(\"請輸入 sy 的值: \"))\n",
    "\n",
    "# 將輸入數據標準化\n",
    "sample_data = scaler.transform([[px_value, py_value, sx_value, sy_value]])\n",
    "sample_data = torch.tensor(sample_data, dtype=torch.float32)\n",
    "\n",
    "# 使用模型進行預測\n",
    "predicted_output = model(sample_data)\n",
    "predicted_x, predicted_y = predicted_output[0].detach().numpy()\n",
    "\n",
    "print(f\"預測的 x 值為: {predicted_x:.3f}\")\n",
    "print(f\"預測的 y 值為: {predicted_y:.3f}\")\n",
    "\n",
    "# 使用預測的x,y值驅動滑台\n",
    "commander = StageCommander('COM3', 38400)\n",
    "\n",
    "commander.set_pulse('X', abs(predicted_x))\n",
    "commander.set_pulse('Y', abs(predicted_y))\n",
    "\n",
    "commander.drive_to_relative_position(predicted_x, predicted_y, wait_time=1.8)\n",
    "\n",
    "# 顯示滑台的座標\n",
    "x_position, y_position = commander.get_position()\n",
    "print(f\"滑台目前的座標: X={x_position:.3f}, Y={y_position:.3f}\")\n",
    "\n",
    "commander.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e45bef2",
   "metadata": {},
   "source": [
    "# 使用鏡頭滑台四特徵輸入預測並驅動滑台"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98389e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import serial\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# 定義神經網路結構\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, 32)\n",
    "        self.layer4 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = torch.relu(self.layer3(x))\n",
    "        return self.layer4(x)\n",
    "\n",
    "# 載入模型參數\n",
    "model = NeuralNetwork(4)\n",
    "model.load_state_dict(torch.load('trained_model20231001.pth'))\n",
    "model.eval()\n",
    "\n",
    "# 載入標準化器\n",
    "data_path = \"C:/Users/user/點位記錄整理.xlsx\"\n",
    "df = pd.read_excel(data_path)\n",
    "features = df[['px', 'py', 'sx', 'sy']].values\n",
    "scaler = StandardScaler().fit(features)\n",
    "\n",
    "class StageCommander:\n",
    "    def __init__(self, port='COM3', baudrate=38400):\n",
    "        self.ser = serial.Serial(port, baudrate)\n",
    "        self.ser.timeout = 0.05\n",
    "        self.current_position = (0, 0)\n",
    "\n",
    "    def send_command(self, command):\n",
    "        self.ser.write((command + '\\r').encode())\n",
    "        time.sleep(0.01)\n",
    "        return self.ser.readline().decode().strip()\n",
    "\n",
    "    def set_pulse(self, axis, pulse):\n",
    "        command = f\"AXI{axis}:PULSe {pulse}\"\n",
    "        response = self.send_command(command)\n",
    "\n",
    "    def drive_to_relative_position(self, x_diff, y_diff):\n",
    "        x_direction = 'X+' if x_diff > 0 else 'X-'\n",
    "        y_direction = 'Y+' if y_diff > 0 else 'Y-'\n",
    "\n",
    "        self.set_pulse('X', abs(x_diff))\n",
    "        self.set_pulse('Y', abs(y_diff))\n",
    "\n",
    "        position = f\"{x_direction}{y_direction}\"\n",
    "        response = self.send_command(f\"GOLI {position}\")\n",
    "\n",
    "        self.current_position = (self.current_position[0] + x_diff, self.current_position[1] + y_diff)\n",
    "        \n",
    "        # 顯示滑台當前位置到小數點後第三位\n",
    "        print(f\"滑台當前位置: ({self.current_position[0]:.3f}, {self.current_position[1]:.3f})\")\n",
    "\n",
    "    def close(self):\n",
    "        self.ser.close()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "tracker = cv2.TrackerCSRT_create()\n",
    "tracking = False\n",
    "frame_count = 0\n",
    "last_position = None\n",
    "\n",
    "commander = StageCommander('COM3', 38400)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Cannot receive frame\")\n",
    "        break\n",
    "\n",
    "    keyName = cv2.waitKey(1)\n",
    "\n",
    "    if keyName == ord('q'):\n",
    "        break\n",
    "    if keyName == ord('a') and not tracking:\n",
    "        area = cv2.selectROI('oxxostudio', frame, showCrosshair=False, fromCenter=False)\n",
    "        tracker.init(frame, area)\n",
    "        tracking = True\n",
    "\n",
    "    if tracking:\n",
    "        success, point = tracker.update(frame)\n",
    "        if success:\n",
    "            p1 = (int(point[0]), int(point[1]))\n",
    "            p2 = (int(point[0] + point[2]), int(point[1] + point[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (0,0,255), 3)\n",
    "\n",
    "            frame_count += 1\n",
    "            if frame_count % 60 == 0:\n",
    "                if last_position:\n",
    "                    px = (p1[0] - last_position[0])\n",
    "                    py = (p1[1] - last_position[1])\n",
    "                    sx, sy = commander.current_position\n",
    "\n",
    "                    # 顯示px, py, sx, sy值\n",
    "                    print(f\"px值: {px:.3f}, py值: {py:.3f}, sx值: {sx:.3f}, sy值: {sy:.3f}\")\n",
    "\n",
    "                    # 標準化輸入數據\n",
    "                    sample_data = scaler.transform([[px, py, sx, sy]])\n",
    "                    sample_data = torch.tensor(sample_data, dtype=torch.float32)\n",
    "\n",
    "                    # 使用模型進行預測\n",
    "                    predicted_output = model(sample_data)\n",
    "                    predicted_x, predicted_y = predicted_output[0].detach().numpy()\n",
    "\n",
    "                    # 顯示預測的x, y值\n",
    "                    print(f\"預測的 x 值為: {predicted_x:.3f}\")\n",
    "                    print(f\"預測的 y 值為: {predicted_y:.3f}\")\n",
    "\n",
    "                    commander.drive_to_relative_position(predicted_x, predicted_y)\n",
    "\n",
    "                last_position = p1\n",
    "\n",
    "    cv2.imshow('oxxostudio', frame)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "commander.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcd239f",
   "metadata": {},
   "source": [
    "# 使用鏡頭滑台四特徵輸入預測並驅動滑台(有設置極限)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6236c74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import serial\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# 定義神經網路結構\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, 32)\n",
    "        self.layer4 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = torch.relu(self.layer3(x))\n",
    "        return self.layer4(x)\n",
    "\n",
    "# 載入模型參數\n",
    "model = NeuralNetwork(4)\n",
    "model.load_state_dict(torch.load('trained_model20231001.pth'))\n",
    "model.eval()\n",
    "\n",
    "# 載入標準化器\n",
    "data_path = \"C:/Users/user/點位記錄整理.xlsx\"\n",
    "df = pd.read_excel(data_path)\n",
    "features = df[['px', 'py', 'sx', 'sy']].values\n",
    "scaler = StandardScaler().fit(features)\n",
    "\n",
    "class StageCommander:\n",
    "    def __init__(self, port='COM3', baudrate=38400):\n",
    "        self.ser = serial.Serial(port, baudrate)\n",
    "        self.ser.timeout = 0.05\n",
    "        self.current_position = (0, 0)\n",
    "\n",
    "    def send_command(self, command):\n",
    "        self.ser.write((command + '\\r').encode())\n",
    "        time.sleep(0.01)\n",
    "        return self.ser.readline().decode().strip()\n",
    "\n",
    "    def set_pulse(self, axis, pulse):\n",
    "        command = f\"AXI{axis}:PULSe {pulse}\"\n",
    "        response = self.send_command(command)\n",
    "\n",
    "    def drive_to_relative_position(self, x_diff, y_diff):\n",
    "        # 計算預測後的位置\n",
    "        predicted_x_position = self.current_position[0] + x_diff\n",
    "        predicted_y_position = self.current_position[1] + y_diff\n",
    "\n",
    "        # 檢查是否超出範圍\n",
    "        if abs(predicted_x_position) >= 49:\n",
    "            x_diff = 49 - self.current_position[0] if predicted_x_position > 0 else -49 - self.current_position[0]\n",
    "        if abs(predicted_y_position) >= 49:\n",
    "            y_diff = 49 - self.current_position[1] if predicted_y_position > 0 else -49 - self.current_position[1]\n",
    "\n",
    "        x_direction = 'X+' if x_diff > 0 else 'X-'\n",
    "        y_direction = 'Y+' if y_diff > 0 else 'Y-'\n",
    "\n",
    "        self.set_pulse('X', abs(x_diff))\n",
    "        self.set_pulse('Y', abs(y_diff))\n",
    "\n",
    "        position = f\"{x_direction}{y_direction}\"\n",
    "        response = self.send_command(f\"GOLI {position}\")\n",
    "\n",
    "        self.current_position = (self.current_position[0] + x_diff, self.current_position[1] + y_diff)\n",
    "        print(f\"滑台當前位置: ({self.current_position[0]:.3f}, {self.current_position[1]:.3f})\")\n",
    "\n",
    "    def close(self):\n",
    "        self.ser.close()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "tracker = cv2.TrackerCSRT_create()\n",
    "tracking = False\n",
    "frame_count = 0\n",
    "last_position = None\n",
    "out_of_range_count = 0\n",
    "\n",
    "commander = StageCommander('COM3', 38400)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Cannot receive frame\")\n",
    "        break\n",
    "\n",
    "    keyName = cv2.waitKey(1)\n",
    "\n",
    "    if keyName == ord('q'):\n",
    "        break\n",
    "    if keyName == ord('a') and not tracking:\n",
    "        area = cv2.selectROI('oxxostudio', frame, showCrosshair=False, fromCenter=False)\n",
    "        tracker.init(frame, area)\n",
    "        tracking = True\n",
    "\n",
    "    if tracking:\n",
    "        success, point = tracker.update(frame)\n",
    "        if success:\n",
    "            p1 = (int(point[0]), int(point[1]))\n",
    "            p2 = (int(point[0] + point[2]), int(point[1] + point[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (0,0,255), 3)\n",
    "\n",
    "            frame_count += 1\n",
    "            if frame_count % 60 == 0:\n",
    "                if last_position:\n",
    "                    px = (p1[0] - last_position[0])\n",
    "                    py = (p1[1] - last_position[1])\n",
    "                    sx, sy = commander.current_position\n",
    "\n",
    "                    print(f\"px值: {px:.3f}, py值: {py:.3f}, sx值: {sx:.3f}, sy值: {sy:.3f}\")\n",
    "\n",
    "                    sample_data = scaler.transform([[px, py, sx, sy]])\n",
    "                    sample_data = torch.tensor(sample_data, dtype=torch.float32)\n",
    "\n",
    "                    predicted_output = model(sample_data)\n",
    "                    predicted_x, predicted_y = predicted_output[0].detach().numpy()\n",
    "                    \n",
    "                    if (commander.current_position[0] + predicted_x > 49 or commander.current_position[0] + predicted_x < -49 or\n",
    "                        commander.current_position[1] + predicted_y > 49 or commander.current_position[1] + predicted_y < -49):\n",
    "                        \n",
    "                        if out_of_range_count == 0:\n",
    "                            print(\"即將超出追蹤範圍，暫停追蹤240針\")\n",
    "                            tracking = False\n",
    "                            time.sleep(240/60)\n",
    "                            out_of_range_count += 1\n",
    "                            \n",
    "                        else:\n",
    "                            print(\"程式終止：超出追蹤範圍\")\n",
    "                            break\n",
    "                    else:\n",
    "                        out_of_range_count = 0\n",
    "                        # 顯示預測的x, y值\n",
    "                        print(f\"預測的 x 值為: {predicted_x:.3f}\")\n",
    "                        print(f\"預測的 y 值為: {predicted_y:.3f}\")\n",
    "                        commander.drive_to_relative_position(predicted_x, predicted_y)\n",
    "                last_position = p1\n",
    "\n",
    "    cv2.imshow('oxxostudio', frame)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "commander.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4953d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90defc02",
   "metadata": {},
   "source": [
    "# 2023.11.27成功追蹤版+結合滑台 (torch環境)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efaca7bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 30: 檢測到的物體: BMW, 置信度: 0.84, 中心點座標: (320, 261)\n",
      "Frame 30: 檢測到的物體: BMW, 置信度: 0.81, 中心點座標: (320, 217)\n",
      "滑台當前位置: (-0.034, -0.694)\n",
      "Frame 60: 檢測到的物體: BMW, 置信度: 0.75, 中心點座標: (320, 223)\n",
      "Frame 60: 檢測到的物體: Ford, 置信度: 0.73, 中心點座標: (320, 240)\n",
      "滑台當前位置: (0.232, -3.393)\n",
      "Frame 90: 檢測到的物體: Ford, 置信度: 0.83, 中心點座標: (320, 231)\n",
      "滑台當前位置: (0.625, -5.200)\n",
      "Frame 120: 檢測到的物體: BMW, 置信度: 0.69, 中心點座標: (334, 223)\n",
      "Frame 120: 檢測到的物體: Ford, 置信度: 0.57, 中心點座標: (325, 199)\n",
      "滑台當前位置: (1.424, -3.809)\n",
      "Frame 150: 檢測到的物體: Ford, 置信度: 0.88, 中心點座標: (320, 223)\n",
      "Frame 150: 檢測到的物體: Ford, 置信度: 0.73, 中心點座標: (117, 240)\n",
      "Frame 150: 檢測到的物體: BMW, 置信度: 0.60, 中心點座標: (329, 220)\n",
      "滑台當前位置: (2.735, -4.598)\n",
      "Frame 180: 檢測到的物體: Ford, 置信度: 0.82, 中心點座標: (90, 214)\n",
      "Frame 180: 檢測到的物體: Ford, 置信度: 0.76, 中心點座標: (319, 234)\n",
      "Frame 180: 檢測到的物體: BMW, 置信度: 0.76, 中心點座標: (343, 189)\n",
      "Frame 180: 檢測到的物體: BMW, 置信度: 0.57, 中心點座標: (372, 251)\n",
      "滑台當前位置: (8.407, -8.277)\n",
      "Frame 210: 檢測到的物體: BMW, 置信度: 0.83, 中心點座標: (319, 288)\n",
      "Frame 210: 檢測到的物體: BMW, 置信度: 0.62, 中心點座標: (341, 224)\n",
      "滑台當前位置: (11.011, -9.554)\n",
      "Frame 240: 檢測到的物體: BMW, 置信度: 0.84, 中心點座標: (318, 288)\n",
      "Frame 240: 檢測到的物體: BMW, 置信度: 0.80, 中心點座標: (337, 218)\n",
      "滑台當前位置: (13.045, -10.152)\n",
      "Frame 270: 檢測到的物體: BMW, 置信度: 0.83, 中心點座標: (337, 187)\n",
      "Frame 270: 檢測到的物體: BMW, 置信度: 0.81, 中心點座標: (318, 289)\n",
      "滑台當前位置: (14.330, -18.350)\n",
      "Frame 300: 檢測到的物體: BMW, 置信度: 0.90, 中心點座標: (327, 187)\n",
      "Frame 300: 檢測到的物體: BMW, 置信度: 0.63, 中心點座標: (317, 290)\n",
      "滑台當前位置: (15.520, -26.467)\n",
      "Frame 330: 檢測到的物體: BMW, 置信度: 0.84, 中心點座標: (320, 185)\n",
      "滑台當前位置: (14.995, -21.889)\n",
      "Frame 360: 檢測到的物體: BMW, 置信度: 0.87, 中心點座標: (320, 186)\n",
      "滑台當前位置: (14.515, -17.733)\n",
      "Frame 390: 檢測到的物體: BMW, 置信度: 0.89, 中心點座標: (320, 187)\n",
      "Frame 390: 檢測到的物體: BMW, 置信度: 0.59, 中心點座標: (317, 291)\n",
      "滑台當前位置: (15.717, -25.997)\n",
      "Frame 420: 檢測到的物體: BMW, 置信度: 0.85, 中心點座標: (320, 185)\n",
      "滑台當前位置: (15.182, -21.455)\n",
      "Frame 450: 檢測到的物體: BMW, 置信度: 0.88, 中心點座標: (320, 186)\n",
      "滑台當前位置: (14.700, -17.324)\n",
      "Frame 480: 檢測到的物體: BMW, 置信度: 0.90, 中心點座標: (320, 187)\n",
      "Frame 480: 檢測到的物體: BMW, 置信度: 0.68, 中心點座標: (317, 291)\n",
      "滑台當前位置: (15.895, -25.621)\n",
      "Frame 510: 檢測到的物體: BMW, 置信度: 0.86, 中心點座標: (320, 186)\n",
      "滑台當前位置: (15.366, -21.219)\n",
      "Frame 540: 檢測到的物體: BMW, 置信度: 0.87, 中心點座標: (320, 186)\n",
      "滑台當前位置: (14.883, -17.102)\n",
      "Frame 570: 檢測到的物體: BMW, 置信度: 0.89, 中心點座標: (320, 186)\n",
      "Frame 570: 檢測到的物體: BMW, 置信度: 0.60, 中心點座標: (317, 292)\n",
      "滑台當前位置: (16.092, -25.526)\n",
      "Frame 600: 檢測到的物體: BMW, 置信度: 0.76, 中心點座標: (320, 185)\n",
      "滑台當前位置: (15.534, -21.020)\n",
      "Frame 630: 檢測到的物體: BMW, 置信度: 0.78, 中心點座標: (334, 218)\n",
      "Frame 630: 檢測到的物體: BMW, 置信度: 0.67, 中心點座標: (320, 257)\n",
      "Frame 630: 檢測到的物體: Ford, 置信度: 0.65, 中心點座標: (317, 227)\n",
      "滑台當前位置: (15.396, -21.866)\n",
      "Frame 660: 檢測到的物體: BMW, 置信度: 0.85, 中心點座標: (320, 213)\n",
      "滑台當前位置: (15.296, -20.992)\n",
      "Frame 690: 檢測到的物體: BMW, 置信度: 0.80, 中心點座標: (320, 213)\n",
      "滑台當前位置: (15.208, -20.183)\n",
      "Frame 720: 檢測到的物體: Ford, 置信度: 0.81, 中心點座標: (320, 230)\n",
      "Frame 720: 檢測到的物體: BMW, 置信度: 0.77, 中心點座標: (332, 222)\n",
      "滑台當前位置: (16.350, -20.680)\n",
      "Frame 750: 檢測到的物體: BMW, 置信度: 0.76, 中心點座標: (371, 211)\n",
      "滑台當前位置: (20.627, -20.319)\n",
      "Frame 780: 檢測到的物體: BMW, 置信度: 0.84, 中心點座標: (325, 185)\n",
      "滑台當前位置: (20.209, -16.241)\n",
      "Frame 810: 檢測到的物體: BMW, 置信度: 0.78, 中心點座標: (320, 217)\n",
      "滑台當前位置: (19.888, -16.242)\n",
      "Frame 840: 檢測到的物體: BMW, 置信度: 0.82, 中心點座標: (320, 187)\n",
      "滑台當前位置: (19.269, -12.618)\n",
      "Frame 870: 檢測到的物體: BMW, 置信度: 0.77, 中心點座標: (320, 220)\n",
      "滑台當前位置: (19.058, -13.214)\n",
      "Frame 900: 檢測到的物體: BMW, 置信度: 0.77, 中心點座標: (320, 219)\n",
      "滑台當前位置: (18.885, -13.671)\n",
      "Frame 930: 檢測到的物體: BMW, 置信度: 0.80, 中心點座標: (320, 217)\n",
      "滑台當前位置: (18.730, -13.869)\n",
      "Frame 960: 檢測到的物體: BMW, 置信度: 0.79, 中心點座標: (320, 215)\n",
      "Frame 960: 檢測到的物體: BMW, 置信度: 0.56, 中心點座標: (316, 292)\n",
      "滑台當前位置: (19.547, -22.528)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import serial\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('C:/Users/user/Yolov7/yolov7')  # 確保這個路徑是正確的\n",
    "from models.yolo import Model  # 導入YOLOv7的Model類\n",
    "import torchvision.transforms as transforms\n",
    "from utils.general import non_max_suppression, scale_coords\n",
    "\n",
    "# 自定義的繪製邊界框和標籤的函數\n",
    "def draw_boxes(frame, boxes, labels, line_width, color):\n",
    "    for box, label in zip(boxes, labels):\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, line_width)\n",
    "        cv2.putText(frame, label, ((x1 + x2) // 2, (y1 + y2) // 2), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "model_config = 'C:/Users/user/Yolov7/yolov7/cfg/training/yolov7_custom.yaml'\n",
    "model_weights = 'C:/Users/user/Yolov7/yolov7/runs/train/exp26/weights/best.pt'\n",
    "\n",
    "class_names = [\"BMW\", \"Fiat\", \"Ford\", \"Honda\", \"Long\", \"Mazda\", \"Mercedes\", \"Nissan\", \"Toyota\", \"Volkswagen\"]\n",
    "frame_counter = 0\n",
    "\n",
    "# 用于跟踪未检测到高置信度物体的次数\n",
    "no_detection_counter = 0\n",
    "\n",
    "# 載入模型配置\n",
    "model = Model(model_config)\n",
    "\n",
    "# 載入預訓練的權重\n",
    "ckpt = torch.load(model_weights, map_location='cpu')\n",
    "model.load_state_dict(ckpt['model'].state_dict())\n",
    "\n",
    "# 定義神經網路結構\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, 32)\n",
    "        self.layer4 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = torch.relu(self.layer3(x))\n",
    "        return self.layer4(x)\n",
    "\n",
    "# 載入模型參數\n",
    "model_nn = NeuralNetwork(4)  # 使用不同名稱避免混淆\n",
    "model_nn.load_state_dict(torch.load('trained_model20231001.pth'))\n",
    "model_nn.eval()\n",
    "\n",
    "# 載入標準化器\n",
    "data_path = \"C:/Users/user/點位記錄整理.xlsx\"\n",
    "df = pd.read_excel(data_path)\n",
    "features = df[['px', 'py', 'sx', 'sy']].values\n",
    "scaler = StandardScaler().fit(features)\n",
    "\n",
    "class StageCommander:\n",
    "    def __init__(self, port='COM3', baudrate=38400):\n",
    "        self.ser = serial.Serial(port, baudrate)\n",
    "        self.ser.timeout = 0.05\n",
    "        self.current_position = (0, 0)\n",
    "\n",
    "    def send_command(self, command):\n",
    "        self.ser.write((command + '\\r').encode())\n",
    "        time.sleep(0.01)\n",
    "        return self.ser.readline().decode().strip()\n",
    "\n",
    "    def set_pulse(self, axis, pulse):\n",
    "        command = f\"AXI{axis}:PULSe {pulse}\"\n",
    "        response = self.send_command(command)\n",
    "\n",
    "    def drive_to_relative_position(self, x_diff, y_diff):\n",
    "        x_direction = 'X+' if x_diff > 0 else 'X-'\n",
    "        y_direction = 'Y+' if y_diff > 0 else 'Y-'\n",
    "\n",
    "        self.set_pulse('X', abs(x_diff))\n",
    "        self.set_pulse('Y', abs(y_diff))\n",
    "\n",
    "        position = f\"{x_direction}{y_direction}\"\n",
    "        response = self.send_command(f\"GOLI {position}\")\n",
    "\n",
    "        self.current_position = (self.current_position[0] + x_diff, self.current_position[1] + y_diff)\n",
    "        \n",
    "        # 顯示滑台當前位置到小數點後第三位\n",
    "        print(f\"滑台當前位置: ({self.current_position[0]:.3f}, {self.current_position[1]:.3f})\")\n",
    "\n",
    "    def close(self):\n",
    "        self.ser.close()\n",
    "\n",
    "# 初始化滑台控制器\n",
    "commander = StageCommander('COM3', 38400)\n",
    "commander.current_position = (0, 0)  # 设置滑台初始位置为 (0,0)\n",
    "\n",
    "# 初始化攝像頭\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"無法打開攝像頭\")\n",
    "    exit()\n",
    "\n",
    "last_position = None\n",
    "frame_counter = 0\n",
    "over_limit_counter = 0  # 追踪超过限制的次数\n",
    "\n",
    "while True:\n",
    "    # 捕獲即時影像\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"無法讀取攝像頭影像\")\n",
    "        break\n",
    "\n",
    "    frame_counter += 1\n",
    "\n",
    "    # 每60個 frame 進行一次檢測\n",
    "    if frame_counter % 30 == 0:\n",
    "        # 將 BGR 影像轉為 RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((640, 480)),  # 假設模型需要的輸入尺寸\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        frame_transformed = transform(frame_rgb)\n",
    "        frame_batch = frame_transformed.unsqueeze(0)\n",
    "\n",
    "        # 進行檢測\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            results = model(frame_batch)\n",
    "\n",
    "            # 處理模型輸出\n",
    "            if isinstance(results, tuple):\n",
    "                predictions = results[0]\n",
    "            else:\n",
    "                predictions = results\n",
    "\n",
    "            # 設置閾值\n",
    "            conf_thres = 0.5\n",
    "            iou_thres = 0.45\n",
    "            classes = None\n",
    "            agnostic_nms = False\n",
    "\n",
    "            # 後處理\n",
    "            pred = non_max_suppression(predictions, conf_thres, iou_thres, classes=classes, agnostic=agnostic_nms)\n",
    "\n",
    "            detected = False\n",
    "            \n",
    "            # 顯示檢測結果\n",
    "            for i, det in enumerate(pred):\n",
    "                if len(det):\n",
    "                    det[:, :4] = scale_coords(frame_batch.shape[2:], det[:, :4], frame.shape).round()\n",
    "\n",
    "                    boxes = []\n",
    "                    labels = []\n",
    "                    for *xyxy, conf, cls in det:\n",
    "                        if conf >= conf_thres:\n",
    "                            detected = True\n",
    "                            x1, y1, x2, y2 = map(int, xyxy)\n",
    "                            label = f'{class_names[int(cls)]}'\n",
    "                            boxes.append([x1, y1, x2, y2])\n",
    "                            labels.append(label)\n",
    "\n",
    "                            # 計算物體中心點座標\n",
    "                            centerX = (x1 + x2) // 2\n",
    "                            centerY = (y1 + y2) // 2\n",
    "\n",
    "                            # 打印資訊\n",
    "                            print(f'Frame {frame_counter}: 檢測到的物體: {label}, 置信度: {conf:.2f}, 中心點座標: ({centerX}, {centerY})')\n",
    "\n",
    "                    draw_boxes(frame, boxes, labels, 5, (0, 255, 0))  # 綠色邊界框和標籤\n",
    "\n",
    "            if not detected:\n",
    "                no_detection_counter += 1\n",
    "                print(f\"Frame {frame_counter}: 沒有檢測到置信度大於0.6的物體。\")\n",
    "                if no_detection_counter >= 20:\n",
    "                    print(\"連續三次没有追踪到置信度大於0.6的物體，中止程式。\")\n",
    "                    break\n",
    "            else:\n",
    "                no_detection_counter = 0\n",
    "\n",
    "        if detected:\n",
    "            # 使用检测到的物体中心点进行XY滑台控制\n",
    "            px, py = centerX, centerY  # CCD所看到的中心坐标\n",
    "            sx, sy = commander.current_position  # 滑台当前的位置\n",
    "\n",
    "            # 标准化输入数据\n",
    "            sample_data = scaler.transform([[px, py, sx, sy]])\n",
    "            sample_data = torch.tensor(sample_data, dtype=torch.float32)\n",
    "\n",
    "            # 使用模型进行预测\n",
    "            predicted_output = model_nn(sample_data)\n",
    "            predicted_x, predicted_y = predicted_output[0].detach().numpy()\n",
    "\n",
    "            # 调整预测移动量以符合限制\n",
    "            if sx + predicted_x > 48:\n",
    "                predicted_x = 48 - sx\n",
    "            elif sx + predicted_x < -48:\n",
    "                predicted_x = -48 - sx\n",
    "\n",
    "            if sy + predicted_y > 48:\n",
    "                predicted_y = 48 - sy\n",
    "            elif sy + predicted_y < -48:\n",
    "                predicted_y = -48 - sy\n",
    "\n",
    "            # 控制XY滑台\n",
    "            commander.drive_to_relative_position(predicted_x, predicted_y)\n",
    "\n",
    "            # 更新滑台当前位置\n",
    "            new_sx = sx + predicted_x\n",
    "            new_sy = sy + predicted_y\n",
    "            commander.current_position = (new_sx, new_sy)\n",
    "\n",
    "            # 检查是否连续超过限制\n",
    "            if abs(new_sx) > 48 or abs(new_sy) > 48:\n",
    "                over_limit_counter += 1\n",
    "                if over_limit_counter >= 5:\n",
    "                    print(\"连续5次超过位置限制，程序中止\")\n",
    "                    break\n",
    "            else:\n",
    "                over_limit_counter = 0\n",
    "\n",
    "        if detected:\n",
    "            draw_boxes(frame, boxes, labels, 3, (0, 255, 0))  # 綠色邊界框和標籤\n",
    "                \n",
    "    cv2.imshow('YOLOv7 Object Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "commander.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316e4fb6",
   "metadata": {},
   "source": [
    "# 成功追蹤版+結合滑台(5frame回報，15frame驅動)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a94d0bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 5: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 10: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 15: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 20: 檢測到的物體: Nissan, 置信度: 0.87, 中心點座標: (192, 311)\n",
      "Frame 25: 檢測到的物體: Nissan, 置信度: 0.82, 中心點座標: (184, 325)\n",
      "Frame 30: 檢測到的物體: Nissan, 置信度: 0.88, 中心點座標: (181, 313)\n",
      "滑台當前位置: (-12.293, -9.267)\n",
      "Frame 35: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 40: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 45: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 50: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 55: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 60: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 65: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 70: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 75: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 80: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 85: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 90: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 95: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 100: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 105: 檢測到的物體: Nissan, 置信度: 0.75, 中心點座標: (142, 150)\n",
      "滑台當前位置: (-26.608, -2.796)\n",
      "Frame 110: 檢測到的物體: Nissan, 置信度: 0.65, 中心點座標: (139, 148)\n",
      "Frame 115: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 120: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 125: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 130: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 135: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 140: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 145: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 150: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 155: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 160: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 165: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 170: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 175: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 180: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 185: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 190: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 195: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 200: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 205: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 210: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 215: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 220: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 225: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 230: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 235: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 240: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 245: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 250: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 255: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 260: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 265: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 270: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 275: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 280: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 285: 檢測到的物體: Nissan, 置信度: 0.60, 中心點座標: (272, 242)\n",
      "滑台當前位置: (-32.296, -4.316)\n",
      "Frame 290: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 295: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 300: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 305: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 310: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 315: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 320: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 325: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 330: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 335: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 340: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 345: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 350: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 355: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 360: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 365: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 370: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 375: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 380: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 385: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 390: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 395: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 400: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 405: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 410: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 415: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 420: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 425: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 430: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 435: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 440: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 445: 檢測到的物體: Nissan, 置信度: 0.68, 中心點座標: (466, 208)\n",
      "Frame 450: 檢測到的物體: Nissan, 置信度: 0.70, 中心點座標: (459, 200)\n",
      "滑台當前位置: (-20.590, -0.871)\n",
      "Frame 455: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 460: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 465: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 470: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 475: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 480: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 485: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 490: 檢測到的物體: Nissan, 置信度: 0.67, 中心點座標: (290, 278)\n",
      "Frame 495: 檢測到的物體: Nissan, 置信度: 0.66, 中心點座標: (286, 276)\n",
      "滑台當前位置: (-24.435, -5.565)\n",
      "Frame 500: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 505: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 510: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 515: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 520: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 525: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 530: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 535: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 540: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 545: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 550: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 555: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 560: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 565: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 570: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 575: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 580: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 585: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 590: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 595: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 600: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 605: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 610: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 615: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 620: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 625: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 630: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 635: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 640: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 645: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 650: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 655: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 660: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 665: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 670: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 675: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 680: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 685: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 690: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 695: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 700: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 705: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 710: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 715: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 720: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 725: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 730: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 735: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 740: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 745: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 750: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 755: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 760: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 765: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 770: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 775: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 780: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 785: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 790: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 795: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 800: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 805: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 810: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 815: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 820: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 825: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 830: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 835: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 840: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 845: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 850: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 855: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 860: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 865: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 870: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 875: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 880: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 885: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 890: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 895: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 900: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 905: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 910: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 915: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 920: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 925: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 930: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 935: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 940: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 945: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 950: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 955: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 960: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 965: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 970: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 975: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 980: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 985: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 990: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 995: 檢測到的物體: Fiat, 置信度: 0.94, 中心點座標: (397, 293)\n",
      "Frame 1000: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1005: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1010: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1015: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1020: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1025: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1030: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1035: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1040: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1045: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1050: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1055: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1060: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1065: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1070: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1075: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1080: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1085: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1090: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1095: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1100: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1105: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1110: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1115: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1120: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1125: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1130: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1135: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1140: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1145: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1150: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1155: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1160: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1165: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1170: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1175: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1180: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1185: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1190: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1195: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1200: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1205: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1210: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1215: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1220: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1225: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1230: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1235: 檢測到的物體: Fiat, 置信度: 0.78, 中心點座標: (433, 266)\n",
      "Frame 1240: 檢測到的物體: Fiat, 置信度: 0.69, 中心點座標: (442, 281)\n",
      "Frame 1245: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1250: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1255: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1260: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1265: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1270: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1275: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1280: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1285: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1290: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1295: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1300: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1305: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1310: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1315: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1320: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1325: 沒有檢測到置信度大於0.6的物體。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 1330: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1335: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1340: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1345: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1350: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1355: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1360: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1365: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1370: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1375: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1380: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1385: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1390: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1395: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1400: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1405: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1410: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1415: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1420: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1425: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1430: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1435: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1440: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1445: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1450: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1455: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1460: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1465: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1470: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1475: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1480: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1485: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1490: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1495: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1500: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1505: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1510: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1515: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1520: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1525: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1530: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1535: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1540: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1545: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1550: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1555: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1560: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1565: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1570: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1575: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1580: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1585: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1590: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1595: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1600: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1605: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1610: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1615: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1620: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1625: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1630: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1635: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1640: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1645: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1650: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1655: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1660: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1665: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1670: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1675: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1680: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1685: 檢測到的物體: Fiat, 置信度: 0.90, 中心點座標: (275, 381)\n",
      "Frame 1690: 檢測到的物體: Fiat, 置信度: 0.87, 中心點座標: (281, 388)\n",
      "Frame 1695: 檢測到的物體: Fiat, 置信度: 0.91, 中心點座標: (282, 384)\n",
      "滑台當前位置: (-26.328, -19.167)\n",
      "Frame 1700: 檢測到的物體: Fiat, 置信度: 0.84, 中心點座標: (291, 381)\n",
      "Frame 1705: 檢測到的物體: Fiat, 置信度: 0.88, 中心點座標: (310, 128)\n",
      "Frame 1710: 檢測到的物體: Fiat, 置信度: 0.86, 中心點座標: (318, 135)\n",
      "滑台當前位置: (-28.207, -8.829)\n",
      "Frame 1715: 檢測到的物體: Fiat, 置信度: 0.87, 中心點座標: (318, 141)\n",
      "Frame 1720: 檢測到的物體: Fiat, 置信度: 0.90, 中心點座標: (361, 354)\n",
      "Frame 1725: 檢測到的物體: Fiat, 置信度: 0.89, 中心點座標: (359, 356)\n",
      "滑台當前位置: (-23.722, -18.987)\n",
      "Frame 1730: 檢測到的物體: Fiat, 置信度: 0.88, 中心點座標: (363, 360)\n",
      "Frame 1735: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1740: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1745: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1750: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1755: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1760: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1765: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1770: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1775: 檢測到的物體: Fiat, 置信度: 0.86, 中心點座標: (309, 184)\n",
      "Frame 1780: 檢測到的物體: Fiat, 置信度: 0.90, 中心點座標: (305, 181)\n",
      "Frame 1785: 檢測到的物體: Fiat, 置信度: 0.86, 中心點座標: (307, 190)\n",
      "滑台當前位置: (-25.937, -13.863)\n",
      "Frame 1790: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1795: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1800: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1805: 檢測到的物體: Fiat, 置信度: 0.66, 中心點座標: (410, 279)\n",
      "Frame 1810: 檢測到的物體: Fiat, 置信度: 0.79, 中心點座標: (410, 282)\n",
      "Frame 1815: 檢測到的物體: Fiat, 置信度: 0.71, 中心點座標: (405, 288)\n",
      "滑台當前位置: (-18.139, -17.429)\n",
      "Frame 1820: 檢測到的物體: Fiat, 置信度: 0.61, 中心點座標: (404, 287)\n",
      "Frame 1825: 檢測到的物體: Fiat, 置信度: 0.81, 中心點座標: (286, 176)\n",
      "Frame 1830: 檢測到的物體: Fiat, 置信度: 0.77, 中心點座標: (289, 184)\n",
      "滑台當前位置: (-21.680, -12.310)\n",
      "Frame 1835: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1840: 檢測到的物體: Fiat, 置信度: 0.67, 中心點座標: (363, 338)\n",
      "Frame 1845: 檢測到的物體: Fiat, 置信度: 0.80, 中心點座標: (364, 337)\n",
      "滑台當前位置: (-16.537, -21.086)\n",
      "Frame 1850: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1855: 檢測到的物體: Fiat, 置信度: 0.66, 中心點座標: (282, 118)\n",
      "Frame 1860: 檢測到的物體: Fiat, 置信度: 0.63, 中心點座標: (283, 118)\n",
      "滑台當前位置: (-20.659, -8.850)\n",
      "Frame 1865: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1870: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1875: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1880: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1885: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1890: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1895: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1900: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1905: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1910: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1915: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1920: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1925: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1930: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1935: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1940: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1945: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1950: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1955: 檢測到的物體: Fiat, 置信度: 0.80, 中心點座標: (345, 387)\n",
      "Frame 1960: 檢測到的物體: Fiat, 置信度: 0.92, 中心點座標: (331, 396)\n",
      "Frame 1965: 檢測到的物體: Fiat, 置信度: 0.93, 中心點座標: (324, 384)\n",
      "滑台當前位置: (-18.293, -22.356)\n",
      "Frame 1970: 檢測到的物體: Fiat, 置信度: 0.91, 中心點座標: (321, 389)\n",
      "Frame 1975: 檢測到的物體: Fiat, 置信度: 0.84, 中心點座標: (261, 155)\n",
      "Frame 1980: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1985: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1990: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 1995: 沒有檢測到置信度大於0.6的物體。\n",
      "Frame 2000: 沒有檢測到置信度大於0.6的物體。\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import serial\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('C:/Users/user/Yolov7/yolov7')  # 確保這個路徑是正確的\n",
    "from models.yolo import Model  # 導入YOLOv7的Model類\n",
    "import torchvision.transforms as transforms\n",
    "from utils.general import non_max_suppression, scale_coords\n",
    "\n",
    "# 自定義的繪製邊界框和標籤的函數\n",
    "def draw_boxes(frame, boxes, labels, line_width, color):\n",
    "    for box, label in zip(boxes, labels):\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, line_width)\n",
    "        cv2.putText(frame, label, ((x1 + x2) // 2, (y1 + y2) // 2), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "         \n",
    "        \n",
    "model_config = 'C:/Users/user/Yolov7/yolov7/cfg/training/yolov7_custom.yaml'\n",
    "model_weights = 'C:/Users/user/Yolov7/yolov7/runs/train/exp29/weights/best.pt'\n",
    "\n",
    "class_names = [\"BMW\", \"Fiat\", \"Ford\", \"Honda\", \"Long\", \"Mazda\", \"Mercedes\", \"Nissan\", \"Toyota\", \"Volkswagen\"]\n",
    "frame_counter = 0\n",
    "\n",
    "# 用於跟踪未檢測到高置信度物體的次數\n",
    "no_detection_counter = 0\n",
    "\n",
    "# 載入模型配置\n",
    "model = Model(model_config)\n",
    "\n",
    "# 載入預訓練的權重\n",
    "ckpt = torch.load(model_weights, map_location='cpu')\n",
    "model.load_state_dict(ckpt['model'].state_dict())\n",
    "\n",
    "# 定義神經網路結構\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, 32)\n",
    "        self.layer4 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = torch.relu(self.layer3(x))\n",
    "        return self.layer4(x)\n",
    "\n",
    "# 載入模型參數\n",
    "model_nn = NeuralNetwork(4)  # 使用不同名稱避免混淆\n",
    "model_nn.load_state_dict(torch.load('trained_model20231001.pth'))\n",
    "model_nn.eval()\n",
    "\n",
    "# 載入標準化器\n",
    "data_path = \"C:/Users/user/點位記錄整理.xlsx\"\n",
    "df = pd.read_excel(data_path)\n",
    "features = df[['px', 'py', 'sx', 'sy']].values\n",
    "scaler = StandardScaler().fit(features)\n",
    "\n",
    "class StageCommander:\n",
    "    def __init__(self, port='COM3', baudrate=38400):\n",
    "        self.ser = serial.Serial(port, baudrate)\n",
    "        self.ser.timeout = 0.05\n",
    "        self.current_position = (0, 0)\n",
    "\n",
    "    def send_command(self, command):\n",
    "        self.ser.write((command + '\\r').encode())\n",
    "        time.sleep(0.01)\n",
    "        return self.ser.readline().decode().strip()\n",
    "\n",
    "    def set_pulse(self, axis, pulse):\n",
    "        command = f\"AXI{axis}:PULSe {pulse}\"\n",
    "        response = self.send_command(command)\n",
    "\n",
    "    def drive_to_relative_position(self, x_diff, y_diff):\n",
    "        x_direction = 'X+' if x_diff > 0 else 'X-'\n",
    "        y_direction = 'Y+' if y_diff > 0 else 'Y-'\n",
    "\n",
    "        self.set_pulse('X', abs(x_diff))\n",
    "        self.set_pulse('Y', abs(y_diff))\n",
    "\n",
    "        position = f\"{x_direction}{y_direction}\"\n",
    "        response = self.send_command(f\"GOLI {position}\")\n",
    "\n",
    "        self.current_position = (self.current_position[0] + x_diff, self.current_position[1] + y_diff)\n",
    "        \n",
    "        # 顯示滑台當前位置到小數點後第三位\n",
    "        print(f\"滑台當前位置: ({self.current_position[0]:.3f}, {self.current_position[1]:.3f})\")\n",
    "\n",
    "    def close(self):\n",
    "        self.ser.close()\n",
    "\n",
    "# 初始化滑台控制器\n",
    "commander = StageCommander('COM3', 38400)\n",
    "commander.current_position = (0, 0)  # 設置滑台初始位置為 (0,0)\n",
    "\n",
    "# 初始化攝像頭\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"無法打開攝像頭\")\n",
    "    exit()\n",
    "\n",
    "last_position = None\n",
    "frame_counter = 0\n",
    "over_limit_counter = 0  # 追踪超過限制的次數\n",
    "\n",
    "while True:\n",
    "    # 捕獲即時影像\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"無法讀取攝像頭影像\")\n",
    "        break       \n",
    "\n",
    "    frame_counter += 1\n",
    "\n",
    "    # 每5個 frame 進行一次檢測\n",
    "    if frame_counter % 5 == 0:\n",
    "        # 將 BGR 影像轉為 RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((640, 480)),  # 假設模型需要的輸入尺寸\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        frame_transformed = transform(frame_rgb)\n",
    "        frame_batch = frame_transformed.unsqueeze(0)\n",
    "\n",
    "        # 進行檢測\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            results = model(frame_batch)\n",
    "\n",
    "            # 處理模型輸出\n",
    "            if isinstance(results, tuple):\n",
    "                predictions = results[0]\n",
    "            else:\n",
    "                predictions = results\n",
    "\n",
    "            # 設置閾值\n",
    "            conf_thres = 0.6\n",
    "            iou_thres = 0.45\n",
    "            classes = None\n",
    "            agnostic_nms = False\n",
    "\n",
    "            # 後處理\n",
    "            pred = non_max_suppression(predictions, conf_thres, iou_thres, classes=classes, agnostic=agnostic_nms)\n",
    "\n",
    "            detected = False\n",
    "            \n",
    "            # 顯示檢測結果\n",
    "            for i, det in enumerate(pred):\n",
    "                if len(det):\n",
    "                    det[:, :4] = scale_coords(frame_batch.shape[2:], det[:, :4], frame.shape).round()\n",
    "\n",
    "                    boxes = []\n",
    "                    labels = []\n",
    "                    for *xyxy, conf, cls in det:\n",
    "                        if conf >= conf_thres:\n",
    "                            detected = True\n",
    "                            x1, y1, x2, y2 = map(int, xyxy)\n",
    "                            label = f'{class_names[int(cls)]}'\n",
    "                            boxes.append([x1, y1, x2, y2])\n",
    "                            labels.append(label)\n",
    "\n",
    "                            # 計算物體中心點座標\n",
    "                            centerX = (x1 + x2) // 2\n",
    "                            centerY = (y1 + y2) // 2\n",
    "\n",
    "                            # 打印資訊\n",
    "                            print(f'Frame {frame_counter}: 檢測到的物體: {label}, 置信度: {conf:.2f}, 中心點座標: ({centerX}, {centerY})')\n",
    "\n",
    "                    if detected:                       \n",
    "                        draw_boxes(frame, boxes, labels, 5, (0, 255, 0))  # 綠色邊界框和標籤\n",
    "\n",
    "            if not detected:\n",
    "                no_detection_counter += 1\n",
    "                print(f\"Frame {frame_counter}: 沒有檢測到置信度大於0.6的物體。\")\n",
    "                if no_detection_counter >= 1000:\n",
    "                    print(\"連續二十次沒有追踪到置信度大於0.6的物體，中止程式。\")\n",
    "                    break\n",
    "            else:\n",
    "                no_detection_counter = 0\n",
    "\n",
    "        if detected and frame_counter % 15 == 0:\n",
    "            # 使用檢測到的物體中心點進行XY滑台控制\n",
    "            px, py = centerX, centerY  # CCD所看到的中心坐標\n",
    "            sx, sy = commander.current_position  # 滑台當前的位置\n",
    "\n",
    "            # 標准化输入數據\n",
    "            sample_data = scaler.transform([[px, py, sx, sy]])\n",
    "            sample_data = torch.tensor(sample_data, dtype=torch.float32)\n",
    "\n",
    "            # 使用模型進行預測\n",
    "            predicted_output = model_nn(sample_data)\n",
    "            predicted_x, predicted_y = predicted_output[0].detach().numpy()\n",
    "\n",
    "            # 調整預測移動量以符合限制\n",
    "            if sx + predicted_x > 48:\n",
    "                predicted_x = 48 - sx\n",
    "            elif sx + predicted_x < -48:\n",
    "                predicted_x = -48 - sx\n",
    "\n",
    "            if sy + predicted_y > 48:\n",
    "                predicted_y = 48 - sy\n",
    "            elif sy + predicted_y < -48:\n",
    "                predicted_y = -48 - sy\n",
    "\n",
    "            # 控制XY滑台\n",
    "            commander.drive_to_relative_position(predicted_x, predicted_y)\n",
    "\n",
    "            # 更新滑台當前位置\n",
    "            new_sx = sx + predicted_x\n",
    "            new_sy = sy + predicted_y\n",
    "            commander.current_position = (new_sx, new_sy)\n",
    "\n",
    "            # 檢查是否連續超過限制\n",
    "            if abs(new_sx) > 48 or abs(new_sy) > 48:\n",
    "                over_limit_counter += 1\n",
    "                if over_limit_counter >= 5:\n",
    "                    print(\"連續5次超過位置限制，終止程式\")\n",
    "                    break\n",
    "            else:\n",
    "                over_limit_counter = 0\n",
    "                \n",
    "    cv2.imshow('YOLOv7 Object Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "commander.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
